{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import load_data\n",
    "\n",
    "FOLDER_PATH = \"sentiment_datasets/projekt2_data\"\n",
    "\n",
    "data_df = load_data(FOLDER_PATH, df_delimiter=\",\")\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"Phrase\"].str.split().str.len().plot(kind=\"hist\", title=\"number of tokens in line distribution\", grid=True, figsize=(10,10), bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data.bert_input_converter import get_proper_input_to_bert\n",
    "from utils.utils_result import save_report, update_fit_params, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN_SEQ = 50\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = get_proper_input_to_bert(data_df, x_label=\"Phrase\", y_label=\"Sentiment\", max_len_seq=MAX_LEN_SEQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameter setting\n",
    "tensorboard_params = None\n",
    "\n",
    "fit_params = {\n",
    "    \"x\": x_train,\n",
    "    \"y\": y_train,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 64,\n",
    "    \"validation_data\": (x_val, y_val) \n",
    "}\n",
    "\n",
    "input_params = {\n",
    "    \"shape\": (MAX_LEN_SEQ, ),\n",
    "    \"dtype\": \"int32\"\n",
    "}\n",
    "\n",
    "test_result_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.models import model_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters setting\n",
    "bert_params_rnn = {\n",
    "    \"trainable\": True,\n",
    "    \"output_dim\": 768,\n",
    "    \"output_type\": \"sequence_output\",\n",
    "    \"signature\": \"tokens\",\n",
    "    \"n_fine_tune_layers\": 3\n",
    "}\n",
    "\n",
    "model_params_bert_rnn = {\n",
    "    \"input_layer\": \"bert_input\",\n",
    "    \"emb_layer\": \"Bert\",\n",
    "    \"input_params\": input_params,\n",
    "    \"emb_params\": bert_params_rnn,\n",
    "    \"out_activation\": \"softmax\",\n",
    "    \"out_units\": np.unique(y_train).shape[0],\n",
    "    \"loss\": \"sparse_categorical_crossentropy\",\n",
    "    \"optimizer\": \"adam\"\n",
    "}\n",
    "model_name = \"model_elmo_rnn\"\n",
    "model_bert_rnn = model_rnn(model_params_bert_rnn)\n",
    "fit_params, markered_path = update_fit_params(fit_params, model_name=model_name, tensorboard_params=tensorboard_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "model_bert_rnn.fit(**fit_params);\n",
    "model_bert_rnn = save_report(model=model_bert_rnn, model_name=model_name, markered_path=markered_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "test_result_dict = evaluation(model=model_bert_rnn, x_test=x_test, y_test=y_test, model_name=model_name, test_result_dict=test_result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.models import model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters setting\n",
    "bert_params_cnn = {\n",
    "    \"trainable\": True,\n",
    "    \"output_dim\": 768,\n",
    "    \"output_type\": \"sequence_output\",\n",
    "    \"signature\": \"tokens\",\n",
    "    \"n_fine_tune_layers\": 3\n",
    "}\n",
    "\n",
    "model_params_bert_cnn = {\n",
    "    \"input_layer\": \"bert_input\",\n",
    "    \"emb_layer\": \"Bert\",\n",
    "    \"input_params\": input_params,\n",
    "    \"emb_params\": bert_params_cnn,\n",
    "    \"out_activation\": \"softmax\",\n",
    "    \"out_units\": np.unique(y_train).shape[0],\n",
    "    \"loss\": \"sparse_categorical_crossentropy\",\n",
    "    \"optimizer\": \"adam\"\n",
    "}\n",
    "model_name = \"model_bert_cnn\"\n",
    "model_bert_cnn = model_cnn(model_params_bert_cnn)\n",
    "fit_params, markered_path = update_fit_params(fit_params, model_name=model_name, tensorboard_params=tensorboard_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "model_bert_cnn.fit(**fit_params);\n",
    "# model_bert_cnn = save_report(model=model_bert_cnn, model_name=model_name, markered_path=markered_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "test_result_dict = evaluation(model=model_bert_cnn, x_test=x_test, y_test=y_test, model_name=model_name, test_result_dict=test_result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Level FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.models import model_ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters setting\n",
    "bert_params_ffnn = {\n",
    "    \"trainable\": True,\n",
    "    \"output_dim\": 768,\n",
    "    \"output_type\": \"pooled_output\",\n",
    "    \"signature\": \"tokens\",\n",
    "    \"n_fine_tune_layers\": 3\n",
    "}\n",
    "\n",
    "model_params_bert_ffnn = {\n",
    "    \"input_layer\": \"bert_input\",\n",
    "    \"emb_layer\": \"Bert\",\n",
    "    \"input_params\": input_params,\n",
    "    \"emb_params\": bert_params_ffnn,\n",
    "    \"out_activation\": \"softmax\",\n",
    "    \"out_units\": np.unique(y_train).shape[0],\n",
    "    \"loss\": \"sparse_categorical_crossentropy\",\n",
    "    \"optimizer\": \"adam\"\n",
    "}\n",
    "model_name = \"model_bert_ffnn\"\n",
    "model_bert_ffnn = model_ffnn(model_params_bert_ffnn)\n",
    "fit_params, markered_path = update_fit_params(fit_params, model_name=model_name, tensorboard_params=tensorboard_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "model_bert_ffnn.fit(**fit_params);\n",
    "model_bert_ffnn = save_report(model=model_bert_ffnn, model_name=model_name, markered_path=markered_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "test_result_dict = evaluation(model=model_bert_ffnn, x_test=x_test, y_test=y_test, model_name=model_name, test_result_dict=test_result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_result import update_common_history_folder, display_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_common_history_folder(\"about_model\")\n",
    "display_results(\"about_models/comparision\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
